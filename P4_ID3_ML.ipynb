{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['outlook', 'temperature', 'humidity', 'wind', 'playtennis'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tennis = pd.read_csv('ID3_dataset.csv')\n",
    "df_tennis.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    return sum([-prob*log(prob,2) for prob in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_of_list(a_list):\n",
    "    cnt = Counter(x for x in a_list)\n",
    "    num_instances = len(a_list)*1.0\n",
    "    probs =[ x/num_instances for x in cnt.values()]\n",
    "    return entropy(probs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(df,split_attributes_name,target_attributes_name):\n",
    "    df_split = df.groupby(split_attributes_name)\n",
    "    nobs = len(df.index)*1.0\n",
    "    df_agg_ent = df_split.agg({target_attributes_name:entropy_of_list,lambda x:len(x)/nobs})[target_attributes_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Given Play Tennis Data Set:\n",
      "\n",
      "      outlook temperature humidity    wind play\n",
      "0      sunny         hot     high    weak   no\n",
      "1      sunny         hot     high  strong   no\n",
      "2   overcast         hot     high    weak  yes\n",
      "3       rain        mild     high    weak  yes\n",
      "4       rain        cool   normal    weak  yes\n",
      "5       rain        cool   normal  strong   no\n",
      "6   overcast        cool   normal  strong  yes\n",
      "7      sunny        mild     high    weak   no\n",
      "8      sunny        cool   normal    weak  yes\n",
      "9       rain        mild   normal    weak  yes\n",
      "10     sunny        mild   normal  strong  yes\n",
      "11  overcast        mild     high  strong  yes\n",
      "12  overcast         hot   normal    weak  yes\n",
      "13      rain        mild     high  strong   no\n",
      "{'outlook': {'overcast': 'yes',\n",
      "             'rain': {'wind': {'strong': 'no', 'weak': 'yes'}},\n",
      "             'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n",
      "outlook\n",
      "dict_keys(['overcast', 'rain', 'sunny'])\n",
      "sunny\n",
      "humidity\n",
      "dict_keys(['high', 'normal'])\n",
      "high\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "#YOutubr\n",
    "def find_entropy(df):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy\n",
    "def find_entropy_attribute(df,attribute):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "    entropy2 = 0\n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "    return abs(entropy2)\n",
    "def find_winner(df):\n",
    "    #Entropy_att = []\n",
    "    IG = []\n",
    "    for key in df.keys()[:-1]:#         Entropy_att.append(find_entropy_attribute(df,key))\n",
    "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
    "    return df.keys()[:-1][np.argmax(IG)] \n",
    "def get_subtable(df, node,value):\n",
    "    return df[df[node] == value].reset_index(drop=True)\n",
    "def buildTree(df,tree=None): \n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name  #Here we build our decision tree  #Get attribute with maximum information gain\n",
    "    node = find_winner(df)#Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
    "    attValue = np.unique(df[node])#Create an empty dictionary to create tree    \n",
    "    if tree is None:                    \n",
    "        tree={}\n",
    "        tree[node] = {}#We make loop to construct a tree by calling this function recursively. #In this we check if the subset is pure and stops if it is pure. \n",
    "    for value in attValue:\n",
    "        subtable = get_subtable(df,node,value)\n",
    "        clValue,counts = np.unique(subtable['play'],return_counts=True)                        \n",
    "        if len(counts)==1:#Checking purity of subset\n",
    "            tree[node][value] = clValue[0]                                                    \n",
    "        else:        \n",
    "            tree[node][value] = buildTree(subtable) #Calling the function recursively               \n",
    "    return tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "df = pd.read_csv('ID3_dataset.csv')\n",
    "print(\"\\n Given Play Tennis Data Set:\\n\\n\",df)\n",
    "tree= buildTree(df)\n",
    "import pprint\n",
    "pprint.pprint(tree)\n",
    "\n",
    "test={'outlook':'sunny','temperature':'hot','humidity':'high','wind':'weak'}\n",
    "def func(test, tree, default=None):\n",
    "    attribute = next(iter(tree)) \n",
    "    print(attribute) \n",
    "    if test[attribute] in tree[attribute].keys():\n",
    "        print(tree[attribute].keys())\n",
    "        print(test[attribute])\n",
    "        result = tree[attribute][test[attribute]]\n",
    "        if isinstance(result, dict):\n",
    "            return func(test, result)\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        return default\n",
    "ans = func(test, tree)\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " outlook = overcast : yes\n",
      " outlook = rain : \t wind = strong : no\n",
      "\t wind = weak : yes\n",
      " outlook = sunny : \t humidity = high : no\n",
      "\t humidity = normal : yes\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# # Define the tennis dataset\n",
    "# data = {\n",
    "#     'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "#     'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
    "#     'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "#     'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
    "#     'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "df = pd.read_csv('ID3_dataset.csv')\n",
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = {}\n",
    "\n",
    "def entropy(target_col):\n",
    "    values, counts = np.unique(target_col, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy_value = sum(-p * math.log2(p) for p in probabilities)\n",
    "    return entropy_value\n",
    "\n",
    "def information_gain(data, attribute, target_attribute):\n",
    "    total_entropy = entropy(data[target_attribute])\n",
    "    values, counts = np.unique(data[attribute], return_counts=True)\n",
    "    weighted_entropy = sum(counts[i] / counts.sum() * entropy(data.where(data[attribute] == value).dropna()[target_attribute]) for i, value in enumerate(values))\n",
    "    information_gain_value = total_entropy - weighted_entropy\n",
    "    return information_gain_value\n",
    "\n",
    "def build_decision_tree(data, original_data, features, target_attribute, parent_node_class=None):\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return np.unique(data[target_attribute])[0]\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute])[np.argmax(np.unique(original_data[target_attribute], return_counts=True)[1])]\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute])[np.argmax(np.unique(data[target_attribute], return_counts=True)[1])]\n",
    "        information_gains = [information_gain(data, feature, target_attribute) for feature in features]\n",
    "        best_feature_index = np.argmax(information_gains)\n",
    "        best_feature = features[best_feature_index]\n",
    "        tree = Node(best_feature)\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = build_decision_tree(sub_data, data, features, target_attribute, parent_node_class)\n",
    "            tree.children[value] = subtree\n",
    "        return tree\n",
    "\n",
    "# Run the ID3 algorithm\n",
    "target_attribute = 'play'\n",
    "decision_tree = build_decision_tree(df, df, df.columns[:-1].tolist(), target_attribute)\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, Node):\n",
    "        for value, child in node.children.items():\n",
    "            print('\\t' * depth, node.attribute, '=', value, ':', end=' ')\n",
    "            print_tree(child, depth + 1)\n",
    "    else:\n",
    "        print(node)\n",
    "\n",
    "print_tree(decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
